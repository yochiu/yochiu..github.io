<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>行情网关</title>
    <link href="/2022/04/26/%E8%A1%8C%E6%83%85%E7%BD%91%E5%85%B3/"/>
    <url>/2022/04/26/%E8%A1%8C%E6%83%85%E7%BD%91%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<h3 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h3><h5 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h5><ul><li>作为入口网关,  为客户端提供一个接入地址,   API网关将用户的请求路由到不同的行情业务服务器上</li><li>提供了服务治理功能,   支持行情服务的降级,   以及流量控制 </li><li>服务监控的完善,  监控数据上报到n9e</li></ul><h5 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h5><ul><li>RPC框架:  Dubbo (2.6.7的版本)</li><li>RPC请求时长.  超时控制<br>业务方调用超时时长为100毫秒</li><li>IO模型  (IO多路复用)</li></ul><h5 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h5><p>降级是为了保证核心服务的稳定而牺牲非核心服务的做法<br>因为机房单数据源问题,   存在机房数据源单点问题.<br>为了保证交易的核心业务,   将路透数据源冗余一份在网关机房.<br>冗余数据存储在redis中,  只包含最新价等行情数据.  </p><p>接口切换规则可通过配置文件获取,  支持本地配置与远程文件配置.  远程文件配置优先于本地配置. 切换规则包括</p><ul><li>全局切换:  针对所有市场的接口进行切换</li><li>市场切换:  针对某个市场下的所有接口切换</li><li>资源切换:  针对到某个资源(接口)切换</li></ul><h5 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h5><p>使用了哨兵限流方案.  是网关服务的一个过滤器组件,   位于整个过滤器的前端,   请求如果超过了限流,   直接被限流器拒绝.<br>开发中采用了apollo跟哨兵限流整合的方案,   支持动态修改限流规则</p><h6 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h6><p>业务方调用网关服务,  网关服务请求下游服务.<br>核心接口的数据(最新价)是换存在服务的内存中<br>业务方的一次RPC请求,  会有两次网络调用<br>在4C8G的机器上.  RPC压测最好结果为:  900QPS.<br>CPU最高到89%.   平均响应为34毫秒,  tp99为95毫秒</p><h6 id="限流方案"><a href="#限流方案" class="headerlink" title="限流方案"></a>限流方案</h6><ul><li>固定窗口限流<br>时间单位 unit 作为一个时间窗口，每个窗口仅允许限制流量内的请求通过<br>缺点:  一个限流时间单位内,   流量有可能超过设置的流量<img src="../网关/1.webp" width="55%" height="55%" /></li><li>滑动窗口限流<br>滑动窗口就是将限流窗口内部切分成一些更小的时间片，然后在时间轴上滑动<br>每次滑动，滑过一个小时间片，就形成一个新的限流窗口，即滑动窗口<br>再在这个滑动窗口上执行固定时间窗口算法</li><li>漏桶限流<br>用户请求先流入到一个特定大小的漏桶中，系统以特定的速率从漏桶中获取请求并处理</li><li>令牌桶限流<br>模拟一个特定大小的桶，然后向桶中以特定的速度放入令牌（token），请求到达后，必须  从桶中取出一个令牌才能继续处理。如果桶中已经没有令牌了，那么当前请求就被限流</li></ul><h5 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h5><p>服务监控采用的skywalking链路监控系统.<br>skywalking的QPS监控并不十分精准,   且视图化效果不是很好<br>为了更好监控QPS,   基于dubbo的过滤器二次开发,   数据上报到n9e上</p><h5 id="dubbo"><a href="#dubbo" class="headerlink" title="dubbo"></a>dubbo</h5><h6 id="dubbo事件派发策略"><a href="#dubbo事件派发策略" class="headerlink" title="dubbo事件派发策略"></a>dubbo事件派发策略</h6><ul><li>默认是all：所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 即worker线程接收到事件后，将该事件提交到业务线程池中，自己再去处理其他事。</li><li>direct：worker线程接收到事件后，由worker执行到底。</li><li>message：只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO线程上执行</li><li>execution：只请求消息派发到线程池，不含响应（客户端线程池），响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行</li><li>connection：在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。</li></ul><h6 id="dubbo线程池"><a href="#dubbo线程池" class="headerlink" title="dubbo线程池"></a>dubbo线程池</h6><ul><li>fixed 固定大小线程池，启动时建立线程，不关闭，一直持有(默认)<br> 默认线程数为200,   任务队列使用的是SynchronousQueue.<br> 超过线程数后,  会阻塞</li><li>cached 缓存线程池，空闲一分钟自动删除，需要时重建。<br>limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。</li><li>eager 优先创建Worker线程池。在任务数量大于corePoolSize但是小于maximumPoolSize时，优先创建Worker来处理任务</li></ul><h6 id="调用方式"><a href="#调用方式" class="headerlink" title="调用方式"></a>调用方式</h6><p>支持同步和异步两种调用方式，其中异步调用还可细分为“有返回值”的异步调用和“无返回值”的异步调用</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>linux性能优化</title>
    <link href="/2022/04/25/linux/"/>
    <url>/2022/04/25/linux/</url>
    
    <content type="html"><![CDATA[<h4 id="linux性能优化"><a href="#linux性能优化" class="headerlink" title="linux性能优化"></a>linux性能优化</h4><h6 id="平均负载"><a href="#平均负载" class="headerlink" title="平均负载"></a>平均负载</h6><p>平均负载指的是当前系统下,  系统中的可运行还有不可中断的平均进程数,  也就是平均活跃进程数.  跟CPU使用率没有直接关系</p><ul><li>可运行的进程:  是指正在使用 CPU 或者正在等待 CPU 的进程,   也就是我们常用 ps 命令看到的,  处于 R 状态（Running 或 Runnable）的进程</li><li>不可中断平均进程:   正处于内核态关键流程中的进程,  并且这些流程是不可打断的,  比如最常见的是等待硬件设备的 I&#x2F;O 响应，也就是我们在 ps 命令中看到的 D 状态(Uninterruptible Sleep,  也称为 Disk Sleep)的进程<br>当平均负载高于 CPU 数量 70% 的时候，应该分析下排查负载高的问题</li></ul><h5 id="平均负载跟CPU使用率关系"><a href="#平均负载跟CPU使用率关系" class="headerlink" title="平均负载跟CPU使用率关系"></a>平均负载跟CPU使用率关系</h5><p>CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应</p><ul><li>CPU 密集型进程, 使用大量 CPU 会导致平均负载升高,  此时这两者是一致的</li><li>I&#x2F;O 密集型进程,  等待 I&#x2F;O 也会导致平均负载升高,  但 CPU 使用率不一定很高</li><li>大量等待 CPU 的进程调度也会导致平均负载升高,  此时的 CPU 使用率也会比较高</li></ul><h4 id="平均负载命令"><a href="#平均负载命令" class="headerlink" title="平均负载命令"></a>平均负载命令</h4><ul><li>uptime:  查看当前系统负载情况</li><li>cat &#x2F;proc&#x2F;cpuinfo:  查看系统的CPU数量,  平均负载指的是逻辑核数<br>总核数 &#x3D; 物理CPU个数 × 每颗物理CPU的核数<br>总逻辑CPU数 &#x3D; 物理CPU个数 × 每颗物理CPU的核数 × 超线程数<br>物理CPU个数指的是: cat &#x2F;proc&#x2F;cpuinfo 来查看,  其中的physical id就是每个物理CPU的ID, 能找到几个physical id就代表计算机实际有几个CPU<br>逻辑CPU个数:  cat &#x2F;proc&#x2F;cpuinfo 来查看,  其中的core 指的就是核心数</li><li>mpstat -P ALL 5 1:  显示所有CPU的指标，并在间隔5秒输出一组数据<img src="../linux/1.png" width="55%" height="55%" /></li><li>pidstat -u 5 1:  间隔5秒后输出一组数据，-u表示CPU指标,  查看的是进程CPU状态<img src="../linux/2.png" width="55%" height="55%" /></li></ul><h4 id="CPU上下文切换过程"><a href="#CPU上下文切换过程" class="headerlink" title="CPU上下文切换过程"></a>CPU上下文切换过程</h4><p>切换任务的时候,  需要记录任务当前的状态和获取下一任务的信息和地址(指针), 这就是上下文的内容。<br>上下文是指某一时间点CPU寄存器和程序计数器的内容,  广义上还包括内存中进程的虚拟地址映射信息.<br>上下文切换的过程：<br>(1)记录当前任务的上下文(即寄存器和计算器等所有的状态)<br>(2)找到新任务的上下文并加载<br>(3)切换到新任务的程序计算器位置,  恢复其任务</p><h4 id="CPU上下文切换场景"><a href="#CPU上下文切换场景" class="headerlink" title="CPU上下文切换场景"></a>CPU上下文切换场景</h4><ul><li>进程间切换: 一个进程切换到另外一个进程,</li></ul><ol><li>进程切换过程:<br> (a)接收到切换信号，挂起进程，记录当前进程的虚拟内存、栈等资源存储;<br>(b)将这个进程在 CPU 中的上下文状态存储于起来;<br>(c)然后在内存中检索下一个进程的上下文;<br>(d)并将其加载到 CPU的寄存器中恢复;<br>(3)还需要刷新进程的虚拟内存和用户栈;<br>(f)最后跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程</li><li>进程切换场景<br>  (a)、根据调度策略,  将CPU时间划片为对应的时间片,  当时间片耗尽,  当前进程必须挂起<br>  (b)、资源不足的,  在获取到足够资源之前进程挂起。<br>  (c)、进程sleep挂起进程<br>  (d)、高优先级进程导致当前进度挂起<br>  (e)、硬件中断,  导致当前进程挂起</li></ol><ul><li>线程间切换:</li></ul><ol><li>线程间切换过程<br> (1)、不同进程之间的线程上下文切换,   其过程和进程上下文切换大致相同<br> (2)、进程内部的线程进上下文切换。不需要切换进程的用户资源，只需要切换线程私有的数据和寄存器等。这会比进程上下文进程切换消耗的资源少，所以多线程相比多进程的优势。</li></ol><ul><li>中断上下文切换:<br> 快速响应硬件的事件,  中断处理会打断进程的正常调度和执行<br> 同一CPU内,  硬件中断优先级高于进程。切换过程类似于系统调用的时候，不涉及到用户运行态资源。但大量的中断上下文切换同样可能引发性能问题。</li><li>中断上下文切换:<br> 快速响应硬件的事件,  中断处理会打断进程的正常调度和执行<br> 同一CPU内,  硬件中断优先级高于进程。切换过程类似于系统调用的时候，不涉及到用户运行态资源。但大量的中断上下文切换同样可能引发性能问题。</li></ul><h4 id="CPU上下文命令"><a href="#CPU上下文命令" class="headerlink" title="CPU上下文命令"></a>CPU上下文命令</h4><ul><li>vmstat 5: 看一下系统的上下文切换次数,  每隔五秒输出一组数据</li></ul><ol><li>r:  就绪队列的长度，也就是正在运行和等待 CPU 的进程数</li><li>b: 处于不可中断睡眠状态的进程数</li><li>cs: 上下文切换次数</li><li>in: 每秒中断的次数<img src="../linux/3.png" width="55%" height="55%" /></li></ol><ul><li>pidstat -w 5: 每隔五秒输出进程上下文切换次数</li></ul><ol><li>cswch&#x2F;s: 每秒自愿上下文切换,  指进程无法获取所需资源,  导致的上下文切换,  比如 I&#x2F;O、内存等系统资源不足时，就会发生自愿上下文切换。而非自愿上下文切换</li><li>nvcswch&#x2F;s:  每秒非自愿上下文切换,  指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换</li></ol><ul><li>pidstat -wt 1:  每隔1秒输出一组数据,   -wt 参数表示输出线程的上下文切换</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MySql</title>
    <link href="/2022/04/06/mysql/"/>
    <url>/2022/04/06/mysql/</url>
    
    <content type="html"><![CDATA[<h1 id="MYSQL"><a href="#MYSQL" class="headerlink" title="MYSQL"></a>MYSQL</h1><h3 id="mysql模块"><a href="#mysql模块" class="headerlink" title="mysql模块"></a>mysql模块</h3><ul><li>连接器: 负责与客户端的连接建立,   获取权限、维持和管理连接.<br>首先会校验账号跟密码,  如果账号密码不对,  再去权限表里校验权限.<br>这意味着已经建立的连接,  如果修改权限,  需要重新建立连接后,  新的权限才能生效</li><li>分析器: 词法分析,  语法分析</li><li>优化器: 执行计划生成, 决定索引的使用</li><li>执行器: 开始执行的时候, 要先判断一下你对这个表T有没有执行查询的权限,  如果没有, 就会返回没有权限的错误.  执行语句查询</li><li>引擎层: 存储数据,  提供读写接口</li></ul><img src="../mysql/1.webp" width="55%" height="55%" /><h3 id="日志模块"><a href="#日志模块" class="headerlink" title="日志模块"></a>日志模块</h3><ul><li>redo log(重做日志):  InnoDB存储引擎持有,   固定大小的文件,  循环写,   用于mysql异常重启恢复数据.  物理日志,   记录的是某个数据项做了什么改动.</li><li>binlog (归档日志):  mysql server层持有,  所有引擎都有, 追加写的文件,   用于mysql恢复到某个时间事件.  逻辑日志,  记录的是原始的sql语句</li></ul><h3 id="数据更新流程"><a href="#数据更新流程" class="headerlink" title="数据更新流程"></a>数据更新流程</h3><p>数据更新流程采用两阶段提交.  是为了保证数据库的状态跟用日志恢复出来的库的状态一致</p><ul><li>redo log用于保证crash-safe能力.   innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘</li><li>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。可以保证MySQL异常重启之后binlog不丢失。</li></ul><img src="../mysql/2.webp" width="55%" height="55%" /><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ul><li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到</li><li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到</li><li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的</li><li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行</li></ul><p>实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准<br>“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图<br>“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的<br>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图</p><h3 id="事务隔离实现"><a href="#事务隔离实现" class="headerlink" title="事务隔离实现"></a>事务隔离实现</h3><p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作, 记录上的最新值<br>通过回滚操作，都可以得到前一个状态的值</p><img src="../mysql/3.webp" width="55%" height="55%" /><p>在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）<br>有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的</p><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul><li>聚簇索引:  也叫主键索引.  叶子结点存储的是整行的数据</li><li>二级索引:  叶子结点存档的是主键索引,  存储的是主键的值</li></ul><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>对于查询语句,  如果索引上包含了所需要的查询字段,   则不需要回表</p><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</p><h3 id="全局锁-表锁"><a href="#全局锁-表锁" class="headerlink" title="全局锁,  表锁"></a>全局锁,  表锁</h3><ul><li>全局锁:  全局锁就是对整个数据库实例加锁,  MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL).   其他语句都会被阻塞<br>全局锁一个应用场景是全库逻辑备份.  但使用FTWRL会影响到业务.<br>备份常用方法:  使用官方的mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的</li><li>表锁:  一种是表锁，一种是元数据锁(MDL).<br>表锁的语法是 lock tables … read&#x2F;write<br>另一类表级的锁是MDL（metadata lock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。 MySQL5.5版本中中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。<br>读锁之间不互斥;   读写锁之间、写锁之间是互斥的.</li></ul><h3 id="两阶段协议"><a href="#两阶段协议" class="headerlink" title="两阶段协议"></a>两阶段协议</h3><p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议</p><h3 id="死锁策略"><a href="#死锁策略" class="headerlink" title="死锁策略"></a>死锁策略</h3><ul><li>直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置.<br>默认为50s</li><li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on</li></ul><h3 id="事务ID"><a href="#事务ID" class="headerlink" title="事务ID"></a>事务ID</h3><p>InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id<br>它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的<br>每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id</p><h3 id="可重复读实现原理"><a href="#可重复读实现原理" class="headerlink" title="可重复读实现原理"></a>可重复读实现原理</h3><p>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的<br>可重复读事务隔离,  是以事务启动时刻为准,  这时事务会拥有一个事务ID,  数据版本是这个时刻(事务ID)之前的版本.  则认,  否则不是这个事务的数据</p><h4 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h4><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为”当前读”（current read)<br>SQL语句加上lock in share mode 或 for update，都是当前读<br>lock in share 是加了读锁(S锁,  共享锁)<br>for update 是加了写锁(X锁,  排他锁)</p><h4 id="普通索引-唯一索引区别"><a href="#普通索引-唯一索引区别" class="headerlink" title="普通索引,  唯一索引区别"></a>普通索引,  唯一索引区别</h4><ul><li>查询过程:  普通索引在找到符合条件的记录时,  会继续往下查找<br>唯一索引,  由于唯一性的约束,  在找到第一条记录的时候,  就结束查找了<br>性能区别:  mysql读数据是以数据页为单位查找的,  当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入.  mysql 数据页大小默认为16KB.<br>因此一条数据页上能存储上千条记录,  查询性能微乎其微</li><li>更新过程:  普通索引使用change buffer记录更新.  唯一索引由于需要校验数据的唯一性,  需要查询数据后,  在更新</li></ul><h4 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h4><p>change buffer用的是buffer pool里的内存，因此不能无限增大<br>change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置<br>这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%  </p><p>数据更新时,  如果数据不在内存中,   更新操作记录在change buffer中<br>下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作<br>将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge<br>系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作</p><h4 id="mysql扫描行数判断"><a href="#mysql扫描行数判断" class="headerlink" title="mysql扫描行数判断"></a>mysql扫描行数判断</h4><p>使用索引的”区分度”来判断行数。一个索引上不同的值越多，这个索引的区分度就越好。<br>而一个索引上不同值的个数，我们称之为”基数”.  这个基数越大，索引的区分度越好<br>索引基数统计:  采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</p><h4 id="刷脏页"><a href="#刷脏页" class="headerlink" title="刷脏页"></a>刷脏页</h4><p>内存数据页跟磁盘数据页内容不一致的时候,   称为脏页.<br>内存数据写入到磁盘后,  内存和磁盘上的数据页的内容就一致了,  称为”干净页”<br>发生脏页的情况: </p><ul><li>redo log日志满了</li><li>内存不够的时候 </li><li>mysql关掉的时候</li><li>系统空闲的时候</li></ul><p>InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：<br>第一种是，还没有使用的；<br>第二种是，使用了并且是干净页；<br>第三种是，使用了并且是脏页。<br>InnoDB的策略是尽量使用内存，<br>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。<br>这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用</p><h4 id="刷脏页策略"><a href="#刷脏页策略" class="headerlink" title="刷脏页策略"></a>刷脏页策略</h4><p>刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个”邻居”也带着一起刷掉； 在InnoDB中，innodb_flush_neighbors 参数就是用来控制这个行为的</p><h4 id="表数据"><a href="#表数据" class="headerlink" title="表数据"></a>表数据</h4><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的</p><ul><li>参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起</li><li>参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中</li></ul><h4 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h4><p>delete 删除数据,   磁盘文件的大小并不会缩小<br>原理:  数据是按数据页存储的,   一个数据页上记录着上千条记录.  当删除一条记录的时候,  只是标志着这条记录被删除了<br>这个数据页上的所有记录都被删除了,  系统会标志这个数据页是可复用的.  但不会回收空间</p><h4 id="select-count-效率问题"><a href="#select-count-效率问题" class="headerlink" title="select count(*)效率问题"></a>select count(*)效率问题</h4><ul><li>count(<em>)是例外，并不会把全部字段取出来, 而是专门做了优化, 不取值。count(</em>)肯定不是null，按行累加</li><li>对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字”1”进去，判断是不可能为空的，按行累加。</li><li>对于count(主键id)来说,  InnoDB引擎会遍历整张表,  把每一行的id值都取出来，返回给server层。server层拿到id后,  判断是不可能为空的,  就按行累加</li><li>对于count(字段)来说：<br> 如果这个”字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为   null，按行累加；<br> 如果这个”字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下, 不是null才累加。</li></ul><h4 id="order-by-工作原理"><a href="#order-by-工作原理" class="headerlink" title="order by 工作原理"></a>order by 工作原理</h4><p>mysql对语句进行排序的时候, MySQL会给每个线程分配一块内存用于排序,  称为sort_buffer<br>排序过程中,  如何查询结果内存大小超过了sort_buffer.  会使用外部排序算法.<br>外部排序一般使用归并排序算法,  将排序的数据分成N份,  每一份单独排序后存在这些临时文件中,  然后把这N份有序文件再合并成一个有序的大文件 </p><h6 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h6><ul><li>初始化sort buffer,   将查询语句的字段放入sort buffer中</li><li>从索引中找到满足条件的主键id</li><li>从主键id中查找结果,  取出字段.  放入sort buffer中</li><li>对sort_buffer中的数据按照排序做快速排序</li><li>取出结果返回给客户端</li></ul><img src="../mysql/4.webp" width="55%" height="55%" /><h6 id="raw-id排序"><a href="#raw-id排序" class="headerlink" title="raw id排序"></a>raw id排序</h6><ul><li>初始化sort_buffer，确定放入查询字段</li><li>从索引city找到第一个主键id</li><li>到主键id索引取出整行，取查询字段，存入sort_buffer中</li><li>从索引city取下一个记录的主键id</li><li>重复步骤3、4直到不满足查询条件为止</li><li>对sort_buffer中的数据按照字段name进行排序；</li><li>遍历排序结果，取前1000行，并按照id的值回到原表中取出查询字段返回给客户端</li></ul><img src="../mysql/5.webp" width="55%" height="55%" /><h4 id="索引不可用情况"><a href="#索引不可用情况" class="headerlink" title="索引不可用情况"></a>索引不可用情况</h4><ul><li>对索引字段使用了函数操作,  会导致索引失效</li><li>如果索引字段为字符串,  查询等值语句使用了整数赋值.  会导致索引不可用<br> 原理:  在MySQL中, 字符串和数字做比较的话,  是将字符串转换成数字</li><li>隐式字符编码转换.  索引字段类型为查询字段类型的子集.  需要对索引字段做转换,   那么会导致索引不可用</li></ul><h4 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h4><ul><li>间隙锁: 锁住的是两个值之间的空隙</li><li>行锁: 锁住的是某个值</li><li>next-key lock:  间隙锁和行锁合称为next-key lock,  每个next-key lock是前开后闭区间</li></ul><h4 id="next-key-lock规则"><a href="#next-key-lock规则" class="headerlink" title="next-key lock规则"></a>next-key lock规则</h4><ul><li>原则1：加锁的基本单位是next-key lock,  next-key lock是前开后闭区间</li><li>原则2：查找过程中访问到的对象才会加锁</li><li>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁</li><li>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁</li><li>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止</li></ul><h4 id="MySQL参数"><a href="#MySQL参数" class="headerlink" title="MySQL参数"></a>MySQL参数</h4><ul><li>max_connections: 用来控制一个MySQL实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示”Too many connections”</li><li>wait_timeout: 一个线程空闲wait_timeout这么多秒之后，就会被MySQL直接断开连接</li></ul><h4 id="binlog写入机制"><a href="#binlog写入机制" class="headerlink" title="binlog写入机制"></a>binlog写入机制</h4><ul><li>事务执行期间,  日志先写到biglog cache.  等事务提交后, 才把binlog cache写到日志中</li><li>每个线程分配给binlog cache分配了一片内存.  参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘</li><li>事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache</li></ul><img src="../mysql/6.webp" width="55%" height="55%" /><p>每个线程一块内存,  但共用一个binlog文件</p><ul><li>write: 是把日志写入到文件系统的page cache,  并没有把数据持久化到磁盘,  所以速度比较快。</li><li>fsync: 将数据持久化到磁盘的操作.  一般情况下,   sync才占磁盘的IOPS</li></ul><p>write 和fsync的时机,  是由sync_binlog参数控制的</p><ul><li>sync_binlog&#x3D;0时, 表示每次提交事务都只write,  不fsync</li><li>sync_binlog&#x3D;1时, 表示每次提交事务都fsync</li><li>sync_binlog&#x3D;N,  表示每次事务都write, 只有累积N个事务之后才fsync</li></ul><p>sync_binlog设置为N，对应的风险是: 如果主机发生异常重启，会丢失最近N个事务的binlog日志</p><h4 id="redolog写入机制"><a href="#redolog写入机制" class="headerlink" title="redolog写入机制"></a>redolog写入机制</h4><p>redolog 状态</p><ul><li>存在redolog buffer中,  这时候是存在mysql 内存中</li><li>写到磁盘(write),  但是没有持久化(fsync),  物理上是在文件系统的page cache里</li><li>持久化到磁盘(fsync)</li></ul><p>redo log的写入策略，由innodb_flush_log_at_trx_commit参数决定</p><ul><li>设置为0的时候,  表示每次事务提交时都只是把redo log留在redo log buffer中</li><li>设置为1的时候,  表示每次事务提交时都将redo log直接持久化到磁盘</li><li>设置为2的时候,   表示每次事务提交时都只是把redo log写到page cache</li></ul><p>redo log持久化场景</p><ul><li>innodb_flush_log_at_trx_commit为1时,  每次事务提交都持久化到磁盘</li><li>InnoDB有一个后台线程, 每隔1秒,  就会把redo log buffer中的日志,  调用write写到文件系统的page cache,  然后调用fsync持久化到磁盘</li><li>redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写磁盘</li><li>并行的事务提交的时，顺带将这个事务的redo log buffer持久化到磁盘。<br>假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时另外一个线程事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时,  就会带上事务A在redo log buffer里的日志一起持久化到磁盘</li></ul><p>每秒一次后台轮询刷盘, 再加上崩溃恢复这个逻辑, InnoDB就认为redo log在commit的时候就不需要fsync了,  只会write到文件系统的page cache中就够了</p><h4 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h4><p>MySQL的”双1”配置,  指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成 1<br>一个事务完整提交前,  需要等待两次刷盘,  一次是redo log(prepare 阶段), 一次是binlog</p><ul><li>日志逻辑序列号(log sequence number, LSN)的概念<br>LSN是单调递增的，用来对应redo log的一个个写入点.  每次写入长度为length的redo log, LSN的值就会加上length</li><li>LSN也会写到InnoDB的数据页中,  来确保数据页不会被多次执行重复的redo log</li></ul><p>如下图所示, 三个并发事务(trx1, trx2, trx3)在prepare 阶段,  都写完redo log buffer，持久化到磁盘的过程,  对应的LSN分别是50、120 和160</p><ul><li>trx1是第一个到达的, 会被选为这组的 leader</li><li>等trx1要开始写盘的时候,  这个组里面已经有了三个事务,  这时候LSN也变成了160</li><li>trx1去写盘的时候, 带的就是LSN&#x3D;160,  因此等trx1返回时, 所有LSN小于等于160的redo log，都已经被持久化到磁盘</li><li>这时候trx2和trx3就可以直接返回了</li></ul><img src="../mysql/8.webp" width="55%" height="55%" /><p>提升binlog组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count来实现</p><ul><li>binlog_group_commit_sync_delay参数,  表示延迟多少微秒后才调用fsync</li><li>binlog_group_commit_sync_no_delay_count参数,  表示累积多少次以后才调用fsync</li></ul><h4 id="两阶段日志提交"><a href="#两阶段日志提交" class="headerlink" title="两阶段日志提交"></a>两阶段日志提交</h4><p>binlog跟redo log的流程其实是如下图所示,<br>binlog的fsync是在redo logcommit之前,  所以binglog也可以采用组提交协议来减少磁盘的IOPS</p><img src="../mysql/8.webp" width="55%" height="55%" /><h4 id="MySQL主备"><a href="#MySQL主备" class="headerlink" title="MySQL主备"></a>MySQL主备</h4><ul><li>备库设置成只读模式,  考虑点<br>运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作<br>防止切换逻辑有bug，比如切换过程中出现双写，造成主备不一致<br>可以用readonly状态，来判断节点的角色<br>readonly设置对超级(super)权限用户是无效的,  而用于同步更新的线程, 就拥有超级权限<br>这样主从就可以正常进行</li></ul><h4 id="MySQL主从同步过程"><a href="#MySQL主从同步过程" class="headerlink" title="MySQL主从同步过程"></a>MySQL主从同步过程</h4><ul><li>备库B上通过change master命令, 设置主库A的IP、端口、用户名、密码, 以及要从哪个位置开始请求binlog, 这个位置包含文件名和日志偏移量</li><li>在备库B上执行start slave命令,  这时候备库会启动两个线程, 就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接</li><li>主库A校验完用户名、密码后,  开始按照备库B传过来的位置, 从本地读取binlog,  发给B</li><li>备库B拿到binlog后,  写到本地文件,  称为中转日志</li><li>sql_thread读取中转日志,  解析出日志里的命令,  并执行</li></ul><img src="../mysql/10.webp" width="55%" height="55%" /><h4 id="binlog格式"><a href="#binlog格式" class="headerlink" title="binlog格式"></a>binlog格式</h4><ul><li>statement格式:  记录到binlog里的是语句原文.  有可能出现主从数据不一致的情况<br> 例如:  delete from t   where a&gt;&#x3D;4 and t_modified&lt;&#x3D;’2018-11-10’ limit 1<br> SQL执行的时候有可能先使用索引a或者索引t_modified</li><li>row格式:  binlog里没有了SQL语句的原文,  而是记录的是数据的改动.   会占用大量的空间</li><li>mix格式:  statement格式和row格式的混搭.  Mysql会根据语句判断是否会引起主从不一致.<br> 如果会引起主从不一致,  使用row格式,   否则使用statement格式</li></ul><h4 id="row格式好处"><a href="#row格式好处" class="headerlink" title="row格式好处"></a>row格式好处</h4><p>便于数据恢复</p><ul><li>执行的是删除语句,  row格式的binlog也会把被删掉的行的整行信息保存起来.  当删错数据了, 可以直接把binlog中记录的delete语句转成insert,  把被错删的数据插入回去就可以恢复了</li><li>执行错了insert语句,  insert语句的binlog里会记录所有的字段信息, 这些信息可以用来精确定位刚刚被插入的那一行.  你直接把insert语句转成delete语句,  删除掉这被误插入的一行数据就可以了</li><li>执行的是update语句的话，binlog里面会记录修改前整行的数据和修改后的整行数据。误执行了update语句的话，只需要把这个event前后的两行信息对调一下, 再去数据库里面执行，就能恢复这个更新操作</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>摄影知识</title>
    <link href="/2022/03/27/%E6%91%84%E5%BD%B1%E7%9F%A5%E8%AF%86/"/>
    <url>/2022/03/27/%E6%91%84%E5%BD%B1%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h3 id="光圈"><a href="#光圈" class="headerlink" title="光圈"></a>光圈</h3><p>F值用来表示光圈大小,  F&#x3D;镜头焦距&#x2F;光圈口径<br>F值小的是大光圈,  F值大的是小光圈<br>光圈除了控制通光量,  还可以控制景深<br>光圈越大,  景深越浅.   光圈越小,  景深越深</p><p>景深:   照片中qing</p><h3 id="焦段"><a href="#焦段" class="headerlink" title="焦段"></a>焦段</h3><p>镜头焦段越长,  景深越小,   视角越窄<br>镜头焦段越短,  景深越大,   视角越光</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis缓冲区</title>
    <link href="/2022/03/23/Redis%E7%BC%93%E5%86%B2%E5%8C%BA/"/>
    <url>/2022/03/23/Redis%E7%BC%93%E5%86%B2%E5%8C%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="Redis缓冲区"><a href="#Redis缓冲区" class="headerlink" title="Redis缓冲区"></a>Redis缓冲区</h3><h5 id="客户端输入输出缓冲区"><a href="#客户端输入输出缓冲区" class="headerlink" title="客户端输入输出缓冲区"></a>客户端输入输出缓冲区</h5><p>服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区</p><p>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理.<br>当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端</p><p>输入输出缓冲区溢出情况</p><ul><li>bigKey的操作</li><li>服务端处理请求操作,  例如发生主线程阻塞情况</li></ul><p>Redis客户端输入缓冲区上线阈值为1GB,   无法进行调整<br>Redis输出缓冲区可以通过client-output-buffer-limit参数进行调整.<br>Redis 输出缓冲区包括两部分：一部分，是一个大小为 16KB 的固定缓冲空间，用来暂存 OK 响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果</p><h4 id="主从集群全量复制缓冲区"><a href="#主从集群全量复制缓冲区" class="headerlink" title="主从集群全量复制缓冲区"></a>主从集群全量复制缓冲区</h4><p>主从全量数据同步时,   主节点会为每个从节点维护一个复制缓冲区,<br>主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求, 这些写命令就会先保存在复制缓冲区中</p><h4 id="主从增量复制缓冲区"><a href="#主从增量复制缓冲区" class="headerlink" title="主从增量复制缓冲区"></a>主从增量复制缓冲区</h4><p>主从集群增量复制时,  主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区<br>当从节点跟主节点恢复连接时,  从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令<br>增量复制缓冲区是一个环形缓冲区.  当发生溢出的时候,  会造成命令被覆盖</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>缓存淘汰策略</title>
    <link href="/2022/03/23/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/"/>
    <url>/2022/03/23/%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<h3 id="Redis缓存淘汰策略"><a href="#Redis缓存淘汰策略" class="headerlink" title="Redis缓存淘汰策略"></a>Redis缓存淘汰策略</h3><ul><li>noeviction:  不进行数据淘汰</li><li>volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。</li><li>volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。-</li><li>volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对</li><li>allkeys-random 策略，从所有键值对中随机选择并删除数据</li><li>allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选</li><li>allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选</li></ul><h3 id="LRU算法"><a href="#LRU算法" class="headerlink" title="LRU算法"></a>LRU算法</h3><p>LRU 算法的全称是Least Recently Used<br>按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中<br>LUR普遍做法是维护一个链表,   链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据<br>对于访问到的数据,   移动到队头.   当链表元素满了,   淘汰队尾的数据</p><p>redis LRu算法不使用链表做法,   而是在RedisObject中维护了一个数据最近访问的时间戳.<br>Redis 在淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合<br>接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去<br>下一次淘汰数据时,   Redis会进行数据挑选.  挑选的数据的lru字段要小于候选集合中最小的 lru 值.<br>当候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru字段值最小的数据淘汰出去 . </p><h3 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h3><p>LFU 缓存策略是为每个数据增加了一个计数器，来统计这个数据的访问次数。<br>当使用 LFU 策略筛选淘汰数据时，会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。<br>如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存</p><p>Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。</p><ul><li>ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；</li><li>counter 值：lru 字段的后 8bit，表示数据的访问次数</li></ul><p>8bit只能保存最多255次.  redis采用了算法来计算counter值</p><ul><li>每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值</li><li>然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1</li></ul><p>counter值的衰减机制</p><ul><li>LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减</li><li>LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位</li><li>LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值</li></ul><h3 id="异步删除"><a href="#异步删除" class="headerlink" title="异步删除"></a>异步删除</h3><p>1、lazy-free是4.0新增的功能，但是默认是关闭的，需要手动开启。<br>2、手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：<br>a) lazyfree-lazy-expire：key在过期删除时尝试异步释放内存<br>b) lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存<br>c) lazyfree-lazy-server-del：执行RENAME&#x2F;MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存<br>d) replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>AOF</title>
    <link href="/2022/03/22/AOF/"/>
    <url>/2022/03/22/AOF/</url>
    
    <content type="html"><![CDATA[<h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><blockquote><ul><li>数据库的写前日志（Write Ahead Log, WAL),   是先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志</li></ul></blockquote><h4 id="AOF记录的内容"><a href="#AOF记录的内容" class="headerlink" title="AOF记录的内容"></a>AOF记录的内容</h4><blockquote><ul><li>数据库的redo log(重做日志),  记录的是修改后的数据.   AOF记录的是数据的执行命令</li><li>AOF日志内容有三个部分,   每部分都是由”$”+数字开头,  后面紧跟着具体的命令、键或值.</li><li>如下图所示,  这个 “*3”表示当前命令有三个部分，这里$表示有多少个字节</li></ul></blockquote><img src="../AOF/0.webp" width="55%" height="55%" /><h4 id="AOF三种策略"><a href="#AOF三种策略" class="headerlink" title="AOF三种策略"></a>AOF三种策略</h4><p>AOF一共有三种策略,  分别是no,  every sec,  always三种策略.</p><ul><li>No 操作系统控制的写回.  每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，  由操作系统决定何时将缓冲区内容写回磁盘。</li><li>Everysec  每秒写回,  每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</li><li>Always  同步写回：每个写命令执行完，立马同步地将日志写回磁盘</li></ul><img src="../AOF/1.webp" width="55%" height="55%" /><p>日志写到内存缓冲区对应的是write操作,  日志写回到磁盘对应的是fsync<br>fsync 需要把日志记录写回到磁盘后才能返回，时间较长<br>write操作只需要写内容到缓冲区,   就可以返回</p><p>Always 是同步写回,  需要确保日志写回到磁盘.  这个策略会阻塞主线程<br>Everysec 是每隔一秒将日志写入磁盘,   这个操作可以异步执行<br>No 写回策略.  是由操作系统决定将缓冲区内容写回磁盘,   这个操作也可以异步执行.</p><img src="../AOF/2.webp" width="55%" height="55%" /><h4 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h4><p>随着命令执行次数的增加,  AOF日志文件会越来越大.<br>AOF日志是命令追加,   可以对AOF命令内容进行精简.  减少AOF日志大小</p><p>AOF是由后台子进程执行操作.<br>主线程仍然将命令写入到AOF文件内容缓冲区,<br>后台子进程会对原来的AOF文件进行数据拷贝,   同时也会将命令写入到AOF重写文件的内容缓冲区.<br>等后台子进程操作完成,   重写日志记录的这些最新操作也会写入新的 AOF 文件<br>此时,   就可以用新的AOF文件代替旧的AOF文件</p><p>后台子进程采用写实复制的功能.  写实复制值的是子进程跟主进程指向相同的内存地址空间,<br>只有当用户对key进行修改时,   主进程就会拷贝这个key对应的内存数据出来,  申请新的内存空间,   然后在上面进行数据修改,  这样就不会影响到原来的数据<br>写实复制:  fork子进程一瞬间是会阻塞主线程的,   文件重写过程中,   用户的对key值修改的越多,  需要申请内存空间,   申请内存空间越长,   也会产生阻塞风险. </p><img src="../AOF/3.webp" width="55%" height="55%" />]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis单线程阻塞点</title>
    <link href="/2022/03/21/Redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E9%98%BB%E5%A1%9E%E7%82%B9/"/>
    <url>/2022/03/21/Redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E9%98%BB%E5%A1%9E%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="Redis单线程阻塞点"><a href="#Redis单线程阻塞点" class="headerlink" title="Redis单线程阻塞点"></a>Redis单线程阻塞点</h1><ul><li>集合的全量查询以及聚合查询.  比如, 复杂度高O(n)的命令查询,  集合的交, 并, 差操作. </li><li>元素的删除操作.  删除的本质是要释放内存空间,   操作系统在释放内存空间时,  需要把释放的内存空间放回一个空闲内存快的链表.  这个操作,  会阻塞应用程序.  对于大key的删除,   需要特别注意</li><li>磁盘的交互操作.   比如AOF日志同步写.    取决于AOF的写回策略.  Always,   同步写回: 每个写命令执行完，立马同步地将日志写回磁盘.  这个写回策略会影响Redis主线程</li><li>RDB文件的加载.   RDB文件的传输跟接受是使用子进程.  但是从库在接受到RDB后,  需要使用FLUSHDB操作.  FLUSHDB操作会阻塞线程</li><li>切片集群的交互.  对于redis cluster集群来说,  切片间哈希槽信息需要在不同切片进行信息交互.  当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移</li></ul><h3 id="redis懒删除"><a href="#redis懒删除" class="headerlink" title="redis懒删除"></a>redis懒删除</h3><ul><li>lazy-free是4.0新增的功能，但是默认是关闭的，需要手动开启<blockquote><ul><li>手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：</li><li>lazyfree-lazy-expire：key在过期删除时尝试异步释放内存</li><li>lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存</li><li>lazyfree-lazy-server-del：执行RENAME&#x2F;MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存</li><li>replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</li></ul></blockquote></li></ul><h3 id="redis过期key删除"><a href="#redis过期key删除" class="headerlink" title="redis过期key删除"></a>redis过期key删除</h3><p>默认情况下,  redis会每隔200毫秒删除一些过期key.  这个删除操作会阻塞主线程,  从4.0版本开始,  可以设置异步删除<br>删除算法如下:</p><ol><li>采样ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除.   ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP默认个数为20.</li><li>如果超过 25% 的key过期了，则重复删除的过程，直到过期 key的比例降至 25% 以下<br>如果对大量的key设置了相同的过期时间,   这个算法,  有可能导致一直阻塞主线程</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis集合统计模式</title>
    <link href="/2022/03/14/Redis%E9%9B%86%E5%90%88%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <url>/2022/03/14/Redis%E9%9B%86%E5%90%88%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="Redis集合统计模式"><a href="#Redis集合统计模式" class="headerlink" title="Redis集合统计模式"></a>Redis集合统计模式</h1><blockquote><p>Redis集合类型常见的统计模式有四种,  分别是聚合统计, 排序统计,  二值状态统计,  基数统计</p></blockquote><h3 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h3><p>聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素<br>比较常见的例子是统计网站新增的用户数,   每天的留存用户数<br>使用一个集合记录所有登陆过的用户.  Set类型,  key值为:  user:id<br>对于每天登陆的用户,  也使用Set类型记录,  key值形式为:  user:id:20220314<br>新增用户:  SDIFFSTORE  user:new user:id:20220314 user:id<br>留存用户: SINTERSTORE user:id:rem user:id:20220314 user:id:20220313</p><h3 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h3><p>比较经典的例子是网站的评论数<br>redis中有序的数据结构有List,  Sort Set<br>使用List会导致相同位置上的元素发生变动<br>Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的<br>可以从评论时间的先后给每条评论设置一个权重值,  保存在Sort Set中</p><h3 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h3><p>这里的二值状态就是指集合元素的取值就只有 0 和 1 两种。<br>比较经典的应用场景是打卡场景,  记录签到（1）或未签到（0）<br>Redis提供了一个扩展的数据类型Bitmap,  可以按照偏移值offset对bit数组的某一个 bit 位进行读和写.<br>记录签到:  setbit  key  offset 1<br>检测是否签到:  getbit key  offset<br>统计签到:  bitcount key </p><h3 id="基数统计"><a href="#基数统计" class="headerlink" title="基数统计"></a>基数统计</h3><p>基数统计就是指统计一个集合中不重复的元素个数<br>统计网页的UV时,  就需要用到基数统计<br>基数统计在Redis里可以使用Set或者Hash的数据结构<br>但数据很多时,  Set跟Hash会占用比较大的数据结构<br>HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小<br>每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数<br>HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>maven跟java版本不匹配</title>
    <link href="/2022/03/14/maven_java/"/>
    <url>/2022/03/14/maven_java/</url>
    
    <content type="html"><![CDATA[<h1 id="maven跟java版本不匹配"><a href="#maven跟java版本不匹配" class="headerlink" title="maven跟java版本不匹配"></a>maven跟java版本不匹配</h1><blockquote><p>周末上线服务的时候,   遇到了maven https问题.   查看服务器系统版本,  发现系统maven版本使用的是3.2.2版本.  老版本不支持https,  于是升级maven版本成3.6.3.  对项目进行手动编译(mvn clean compile),   发现报错信息:  Fatal error compiling: invalid target release: 1.8</p></blockquote><p>查看网上信息,   说的是服务使用的java 版本不对.   项目里指定了使用了1.8的JDK版本.<br>查看服务器上,  使用的是java1.7版本.<br>当时,  这台服务上也部署了其他进程,   当时也郁闷,   部门里统一使用的JDK版本都是1.8.<br>为啥其他服务就没有这个问题.<br>又由于当时着急部署服务,   没敢花太多时间追查问题,   就将服务器1.7的JDK升级成了1.8<br>后续部署服务就成功了</p><ul><li>事后想了想,  这样的操作比较危险,   就将这样的问题反馈给了部门负责人,  担心会影响到其他服务,  也将其他进程一一重启.    后续虽然没啥问题,  但现在回想起来还是有点蛮撞</li><li>后续也对项目进行了问题排查.   为啥其他进程部署没啥问题,   而这个服务部署却有问题</li></ul><p>查看项目, 项目里使用了maven-compiler-plugin插件<br>查看网上关于maven-compiler-plugin插件的详解.<br>maven是个项目管理工具,   如果不告诉代码要使用什么样的版本号,  会默认使用maven-compile-plugin插件指定的版本号.  项目里已经指定了JDK1.8的版本号</p><p>查看机器当时的maven使用的版本号为1.7,    使用了版本号对不上的问题.  这就是当时报错的问题</p><figure class="highlight dust"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs dust"><span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span></span><br><span class="language-xml">   <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span></span><br><span class="language-xml">   <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span></span><br><span class="language-xml">   <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.5.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span></span><br><span class="language-xml">   <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="language-xml">         <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>$</span><span class="hljs-template-variable">&#123;java.version&#125;</span><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span></span><br><span class="language-xml">         <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>$</span><span class="hljs-template-variable">&#123;java.version&#125;</span><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span></span><br><span class="language-xml">         <span class="hljs-tag">&lt;<span class="hljs-name">encoding</span>&gt;</span>$</span><span class="hljs-template-variable">&#123;project.build.sourceEncoding&#125;</span><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">encoding</span>&gt;</span></span><br><span class="language-xml">   <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></span><br><span class="language-xml"><span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span>         </span><br></code></pre></td></tr></table></figure><p>那为啥其他服务部署没有问题呢,   查看部署脚本.<br>发现部署脚本将jdk1.8配置进入环境变量.   maven编译打包的时候,   使用的是就是jdk1.8版本.<br>而自己手动编译项目时,  maven使用的是jdk1.7的版本.  这就是为啥手动编译出现了问题</p> <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"> <span class="hljs-built_in">export</span> <span class="hljs-attribute">JAVA_HOME</span>=/usr/local/jdk1.8.0_161<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">JRE_HOME</span>=<span class="hljs-variable">$JAVA_HOME</span>/jre<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-variable">$JAVA_HOME</span>/bin:$PATH<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Redis字符串数据结构</title>
    <link href="/2022/03/12/redis_string/"/>
    <url>/2022/03/12/redis_string/</url>
    
    <content type="html"><![CDATA[<h1 id="Redis字符串数据结构"><a href="#Redis字符串数据结构" class="headerlink" title="Redis字符串数据结构"></a>Redis字符串数据结构</h1><blockquote><p>Redis字符串使用了RedisObject跟SDS的数据结构来保存数据. </p></blockquote><h3 id="Redis-key-value数据结构"><a href="#Redis-key-value数据结构" class="headerlink" title="Redis key_value数据结构"></a>Redis key_value数据结构</h3><p>Redis使用了全局哈希表来保存所有键值对.  哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对.<br>dictEntry 结构中有三个 8 字节的指针, 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节.</p><img src="../redis_string/1.webp" width="55%" height="55%" /><p>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p><h3 id="Redis-SDS数据结构"><a href="#Redis-SDS数据结构" class="headerlink" title="Redis SDS数据结构"></a>Redis SDS数据结构</h3><p>当数据类型包含字符串时,   Redis会使用SDS数据结构来存储这些数据.<br>SDS数据结构有以下三个字段</p><ul><li>buf: 字节数据,  保存实际数据.  Redis会在最后数组最后加一个”\0””,  会占用一个字节</li><li>len: 表示buf已用长度,  占用四个字节</li><li>alloc: 占个 4 字节，表示 buf 的实际分配长度，一般大于 len</li></ul><img src="../redis_string/2.webp" width="55%" height="55%" /><h3 id="RedisObject数据结构"><a href="#RedisObject数据结构" class="headerlink" title="RedisObject数据结构"></a>RedisObject数据结构</h3><blockquote><p>Redis的数据类型很多,  不同的数据类型都有些元数据需要记录. Redis会使用RedisObject结构体来统一记录这些元数据,  同时指向实际数据</p></blockquote><p>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在.</p><p>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在.<br>元数据包括了 type、encoding、lru 和 refcount 4 个元数据</p><ul><li>type: 表示数据类型</li><li>encoding:  是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等；</li><li>lru: 记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对</li><li>refcount: 记录了对象的引用计数</li></ul><img src="../redis_string/3.webp" width="55%" height="55%" /><img src="../redis_string/5.webp" width="55%" height="55%" /><h3 id="RedisObject编码格式"><a href="#RedisObject编码格式" class="headerlink" title="RedisObject编码格式"></a>RedisObject编码格式</h3><ul><li>int编码.   保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数</li><li>embstr编码.  保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片</li><li>raw编码.  当字符串大于 44 字节时，SDS 的数据量就开始变多了.   会使用指针指向SDS结构</li></ul><img src="../redis_string/4.webp" width="55%" height="55%" />]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
